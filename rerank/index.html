<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1,maximum-scale=2,viewport-fit=cover"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta name="renderer" content="webkit"><meta name="author" content="SimonAKing"><link rel="icon" type="image/x-icon" href="https://cdn.jsdelivr.net/gh/SimonAKing/images/blog/favicon.ico"><link rel="shortcut icon" type="image/x-icon" href="https://cdn.jsdelivr.net/gh/SimonAKing/images/blog/favicon.ico"><link rel="apple-touch-icon" href="https://cdn.jsdelivr.net/gh/SimonAKing/images/PWA/apple-touch-icon.png"><title>聊聊 Rerank：从 BERT 到大模型的技术旅程</title><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/SimonAKing/font/comic.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-roboto@1.1.13/index.min.css"><link id="style" rel="stylesheet" href="https://cdn.jsdelivr.net/gh/SimonAKing/blog@7d04115230169/css/style-eaf373873c.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/SimonAKing/blog@7d04115230169/css/post-04c1b3d7ed.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/SimonAKing/blog@7d04115230169/css/module/relatedPosts-1fcaaf0adb.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/SimonAKing/blog@7d04115230169/css/module/comment-2c4172461a.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/firacode@5.2.0/distr/fira_code.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/SimonAKing/blog@7d04115230169/css/highlight-d6d2f7ba38.css"><meta name="theme-color"><meta name="apple-mobile-web-app-status-bar-style"><meta name="msapplication-navbutton-color"><script>
	window.selectedColor = ''
	window.themeColor = localStorage.getItem("theme-color") || "#5275b0"
	window.changeColor = function(themeColor){
		document.documentElement.style.setProperty('--theme-color', themeColor);
		document.querySelector("meta[name=theme-color]").setAttribute("content", themeColor);
		document.querySelector("meta[name=apple-mobile-web-app-status-bar-style]").setAttribute("content", themeColor);
		document.querySelector("meta[name=msapplication-navbutton-color]").setAttribute("content", themeColor);
		localStorage.setItem('theme-color', themeColor)
	}
	changeColor(themeColor)

	window.isPhone = /Android|iOS|iPhone|iPad|iPod|Windows Phone|KFAPWI/i.test(navigator.userAgent) || (window.innerWidth < 1300)
	window.isHome = false
	window.isPost = true
	if(window.isPost){
		window.isReward = true
		window.isWeibo = false
	}
</script><link rel="manifest" href="https://simonaking.com/manifest.json"><meta name="mobile-web-app-capable" content="yes"><meta name="mobile-web-app-title" content="SimonAKing"><meta name="msapplication-starturl" content="https://simonaking.com"><meta name="application-name" content="SimonAKing"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="SimonAKing"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="prefetch" href="https://cdn.jsdelivr.net/"><link rel="dns-prefetch" href="https://api.github.com/"><script async src="https://www.googletagmanager.com/gtag/js?id=UA-109696496-3"></script><script>
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'UA-109696496-3');
</script><link rel="canonical" href="https://simonaking.com/blog/rerank/"><link rel="alternate" type="application/atom+xml" title="SimonAKing" href="/blog/atom.xml"><meta property="og:title" content="聊聊 Rerank：从 BERT 到大模型的技术旅程 | SimonAKing"><meta property="og:site_name" content="SimonAKing"><meta property="og:type" content="article"><meta property="og:url" content="https://simonaking.com/blog/rerank/"><meta property="og:locale" content="zh-CN"><meta name="description" content="在 NLP 场景中，Rerank 作为一个关键环节，承担着对多路召回、多数据来源、多模态、多结构等不同类型数据的归一化和精筛作用。它能有效地整合和优化各类召回结果，对提升检索系统的整体性能至关重要。 - SimonAKing - SimonAKing"><meta name="keywords" content="Rerank,BERT,LLM,大模型,LLM,Rerank,SimonAKing,Blog,博客"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/SimonAKing/blog/rerank/overall.png"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/SimonAKing/blog/rerank/timeline.png"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/SimonAKing/blog/rerank/badcase.png"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/SimonAKing/blog/rerank/Influence.png"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/SimonAKing/blog/rerank/p1.png"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/SimonAKing/blog/rerank/p2.png"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/SimonAKing/blog/rerank/p3.png"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/SimonAKing/blog/rerank/p4.png"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/SimonAKing/blog/rerank/p5.png"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/SimonAKing/blog/rerank/p6.png"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/SimonAKing/blog/rerank/p7.png"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/SimonAKing/blog/rerank/p8.png"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/SimonAKing/blog/rerank/p9.png"><meta property="article:published_time" content="2024-12-09T10:40:53.000Z"><meta property="article:modified_time" content="2025-05-02T08:30:48.354Z"><meta property="og:updated_time" content="2025-05-02T08:30:48.354Z"><meta property="article:author" content="SimonAKing"><meta property="article:tag" content="Rerank,BERT,LLM,大模型,LLM,Rerank,SimonAKing,Blog,博客"><meta name="twitter:card" content="summary"><meta name="twitter:site" content="https:&#x2F;&#x2F;simonaking.com&#x2F;blog&#x2F;rerank&#x2F;"><meta name="twitter:creator" content="SimonAKing"><script type="application/ld+json">
{
    "@context": "http://schema.org",
    "url": "https://simonaking.com/blog/rerank/",
    "@type": "BlogPosting",
    "logo": "https://simonaking.com/images/PWA/192.png",
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "https://simonaking.com/blog/rerank/"
    },
    "headline": "聊聊 Rerank：从 BERT 到大模型的技术旅程 | SimonAKing",
    "image": {
        "@type": "ImageObject",
        "url": "https://simonaking.com/images/PWA/192.png"
    },
    "datePublished": "2024-12-09T10:40:53.000Z",
    "dateModified": "2025-05-02T08:30:48.354Z",
    "author": {
        "@type": "Person",
        "name": "SimonAKing",
        "image": {
            "@type": "ImageObject",
            "url": "https://cdn.jsdelivr.net/gh/SimonAKing/images/blog/avatar.jpg"
        },
        "description": "STDIN | Think &gt;&gt; /dev/Mind"
    },
    "publisher": {
        "@type": "Organization",
        "name": "SimonAKing",
        "logo": {
            "@type": "ImageObject",
            "url": "https://simonaking.com/images/PWA/192.png"
        }
    },
    "keywords": "Rerank,BERT,LLM,大模型,LLM,Rerank,SimonAKing,Blog,博客",
    "description": "在 NLP 场景中，Rerank 作为一个关键环节，承担着对多路召回、多数据来源、多模态、多结构等不同类型数据的归一化和精筛作用。它能有效地整合和优化各类召回结果，对提升检索系统的整体性能至关重要。 - SimonAKing - SimonAKing"
}
</script><!--[if lt IE 9]><style> .alert { padding: 15px; margin-bottom: 20px; border: 1px solid transparent; border-radius: 4px } .alert-danger { background-color: #f2dede; border-color: #ebccd1; color: #a94442; border-bottom: 1px solid #ebccd1 } .alert-link { color: #843534; font-weight: bold } .topframe { margin: 0; padding-left: 15px; padding-right: 15px; text-align: center; border-radius: 0; position: fixed; left: 0; right: 0; top: 0; z-index: 1000 } </style><div class="alert alert-danger topframe"> 你的浏览器实在<strong>太太太太太太旧了</strong>，放学别走，升级完浏览器再说！ <a target="_blank" class="alert-link" href="//browsehappy.com">立即升级</a></div><script src="https://cdn.bootcss.com/html5shiv/r29/html5.min.js"></script><script src="https://cdn.bootcss.com/respond.js/1.4.2/respond.min.js"></script><![endif]--></head><body itemscope itemtype="http://schema.org/WebPage"><aside id="menu" class="hide"><div class="inner flex-row-vertical"><div class="brand-wrap" itemprop="author" itemscope itemtype="http://schema.org/Person"><div class="brand fade"> <a class="avatar waves-effect waves-circle waves-light"><img src="https://cdn.jsdelivr.net/gh/SimonAKing/images/blog/avatar.jpg" title="avatar" alt="avatar" itemprop="image"></a><div class="introduce"><h5 class="nickname " id="name">SimonAKing</h5><div class="links-of-author fade"><span class="links-of-author-item" id="link-wechat"><a href="javascript:void(0)" rel="noopener noreferrer" title="Wechat"><i class="icon icon-lg icon-wechat"></i></a></span><span class="links-of-author-item"><a href="mailto:hi@simonaking.com" rel="noopener noreferrer" target="_blank" title="Email"><i class="icon icon-lg icon-email"></i></a></span><span class="links-of-author-item"><a href="https://x.com/simon_aking" rel="external nofollow noopener noreferrer" target="_blank" title="X"><i class="icon icon-lg icon-XTwitter"></i></a></span><span class="links-of-author-item"><a href="https://github.com/SimonAKing" rel="external nofollow noopener noreferrer" target="_blank" title="Github"><i class="icon icon-lg icon-github"></i></a></span></div><div class="statistics"><ul><li><a class="total-link" href="/blog/weibo/"><div class="count" id="weibo-count">∞</div><div class="type">微博</div></a></li><li><a class="total-link" href="/blog/archives/"><div class="count">32</div><div class="type">文章</div></a></li><li><a class="total-link" href="/gallery/"><div class="count" id="photo-count">∞</div><div class="type">相册</div></a></li></ul></div></div></div></div><div class="scroll-wrap flex-col"><ul class="nav fade"><li class="items waves-block waves-effect"><a href="/blog/"><i class="icon icon-lg icon-xiazai45"></i> <span style="font-size:1em">主 页</span><i class="icon icon-lg icon-chevronleft custom-caret-left"></i></a></li><li class="items waves-block waves-effect"><a href="/blog/archives/"><i class="icon icon-lg icon-guidangxiangmu"></i> <span style="font-size:1em">归 档</span><i class="icon icon-lg icon-chevronleft custom-caret-left"></i></a></li><li class="items waves-block waves-effect"><a href="/blog/tags/"><i class="icon icon-lg icon-biaoqian"></i> <span style="font-size:1em">标 签</span><i class="icon icon-lg icon-chevronleft custom-caret-left"></i></a></li><li class="items waves-block waves-effect"><a href="/blog/weibo/"><i class="icon icon-lg icon-biaoqing"></i> <span style="font-size:1em">微 博</span><i class="icon icon-lg icon-chevronleft custom-caret-left"></i></a></li><li class="items waves-block waves-effect"><a href="//simonaking.com/gallery/"><i class="icon icon-lg icon-xiangce"></i> <span style="font-size:1em">相 册</span><i class="icon icon-lg icon-chevronleft custom-caret-left"></i></a></li><li class="items waves-block waves-effect"><a href="//simonaking.com/about/"><i class="icon icon-lg icon-zhifeiji"></i> <span style="font-size:1em">关 于</span><i class="icon icon-lg icon-chevronleft custom-caret-left"></i></a></li><li class="items waves-block waves-effect"><a href="//simonaking.com/projects/"><i class="icon icon-lg icon-projects"></i> <span style="font-size:1em">项 目</span><i class="icon icon-lg icon-chevronleft custom-caret-left"></i></a></li><li class="items waves-block waves-effect"><a href="//thinking.simonaking.com/" target="_blank" rel="noopener"><i class="icon icon-lg icon--Idea"></i> <span style="font-size:1em">思 考</span><i class="icon icon-lg icon-chevronleft custom-caret-left"></i></a></li><li class="items waves-block waves-effect"><a href="//simonaking.com"><i class="icon icon-lg icon-icon--"></i> <span style="font-size:1em">导航</span><i class="icon icon-lg icon-chevronleft custom-caret-left"></i></a></li><div class="sliding-bar"></div></ul><div class="nav-tool"><a class="nav-tool-item exchange" data-title="简繁互换" href="javascript:translatePage();"><i class="fade icon icon-lg icon-zhuanhuan custom-exchange"></i></a><a class="nav-tool-item picker" data-title="调色板" id="color-picker-icon"><i class="fade icon icon-lg icon-color-palette-outlin custom-picker"></i></a><a class="nav-tool-item light" data-title="关灯" href="javascript:switchNightMode();"><i class="fade icon icon-lg icon-lightbulbo custom-lightbulb"></i></a></div></div></div></aside><main id="main" class="in_post"><header class="top-header in_post" id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="flex-row"><a href="javascript:;" class="header-icon waves-effect waves-circle waves-light on" id="menu-toggle"><i class="icon icon-lg icon-naviconround"></i></a><div class="flex-col"></div><div class="search-wrap" id="search-wrap"><a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="back"><i class="icon icon-lg icon-chevronleft"></i></a> <input type="text" id="key" aria-label="search" class="search-input" autocomplete="off" placeholder="输入感兴趣的关键字"><a href="javascript:;" title="搜索" class="header-icon waves-effect waves-circle waves-light" id="search"><i class="icon icon-lg icon-search"></i></a></div></div><div class="header-title ellipsis">聊聊 Rerank：从 BERT 到大模型的技术旅程</div></header><header class="content-header post-header"><canvas class="flickering-grid-canvas"></canvas></header><div class="container body-wrap"><aside class="post-widget"><nav class="post-toc-wrap fade" id="post-toc"><ol class="post-toc"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#前言"><span class="post-toc-number">1.</span> <span class="post-toc-text">前言</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#正文"><span class="post-toc-number">2.</span> <span class="post-toc-text">正文</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#什么是-Rerank"><span class="post-toc-number">2.1.</span> <span class="post-toc-text">什么是 Rerank</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#业界实践"><span class="post-toc-number">2.2.</span> <span class="post-toc-text">业界实践</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#Passage-Re-ranking-with-BERT"><span class="post-toc-number">2.2.1.</span> <span class="post-toc-text">Passage Re-ranking with BERT</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#Document-Ranking-with-a-Pretrained-Sequence-to-Sequence-Model"><span class="post-toc-number">2.2.2.</span> <span class="post-toc-text">Document Ranking with a Pretrained Sequence-to-Sequence Model</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#Is-ChatGPT-Good-at-Search-Investigating-Large-Language-Models-as-Re-Ranking-Agents"><span class="post-toc-number">2.2.3.</span> <span class="post-toc-text">Is ChatGPT Good at Search? Investigating Large Language Models as Re-Ranking Agents</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#Large-Language-Models-are-Effective-Text-Rankers"><span class="post-toc-number">2.2.4.</span> <span class="post-toc-text">Large Language Models are Effective Text Rankers</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#Leveraging-Passage-Embeddings-for-Efficient-Listwise-Reranking-with-Large-Language-Models"><span class="post-toc-number">2.2.5.</span> <span class="post-toc-text">Leveraging Passage Embeddings for Efficient Listwise Reranking with Large Language Models</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#业界进展"><span class="post-toc-number">2.2.6.</span> <span class="post-toc-text">业界进展</span></a></li></ol></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#结束语"><span class="post-toc-number">3.</span> <span class="post-toc-text">结束语</span></a></li></ol></nav></aside><article id="post-聊聊 Rerank-从BERT到大模型的技术旅程" class="post-article article-type-post fade" itemscope itemtype="http://schema.org/Article"><div class="post-card"><h1 class="post-card-title" itemprop="name headline">&nbsp;</h1><script>
			window.addEventListener('DOMContentLoaded', function (){ var postTitle = document.querySelector('.post-card-title'); var typingbefore = '聊聊 Rerank：从 BERT 到大模型的技术旅程'; var _i = 0; function typetitle() { if (_i <= typingbefore.length) { postTitle.innerHTML = `${typingbefore.slice(0, _i++)}|`; setTimeout(typetitle, 120); } else { postTitle.innerHTML = typingbefore; } } typetitle(); })
		</script><div class="post-meta"><div class="post-category-phone"><ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/blog/categories/LLM/">LLM</a></li></ul></div> <time itemprop="dateCreated datePublished" class="post-time" title="2024-12-09 18:40:53" datetime="2024-12-09T10:40:53.000Z">2024-12-09</time></div><link itemprop="mainEntityOfPage" href="https://simonaking.com/blog/rerank/" style="display:none"><div class="post-content" id="post-content" itemprop="articleBody"><p>从搜索引擎到大语言模型，Rerank 技术一直在默默发挥着”最后一公里”的关键作用。</p><a id="more"></a><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在 NLP 场景中，Rerank 作为一个关键环节，承担着对多路召回、多数据来源、多模态、多结构等不同类型数据的归一化和精筛作用。它能有效地整合和优化各类召回结果，对提升检索系统的整体性能至关重要。</p><p>本文将介绍 rerank 相关的技术概念、业界进展，以及对业务 产生价值的可能性。</p><figure class="image-bubble"><div class="img-lightbox"><div class="overlay"></div> <img src="https://cdn.jsdelivr.net/gh/SimonAKing/images/loading/2-min.gif" alt="image" title="Rerank-从 BERT 到大模型的技术旅程/overall.png" data-original="https://cdn.jsdelivr.net/gh/SimonAKing/blog/rerank/overall.png"></div><div class="image-caption">Rerank-从 BERT 到大模型的技术旅程/overall.png</div></figure><h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><h3 id="什么是-Rerank"><a href="#什么是-Rerank" class="headerlink" title="什么是 Rerank"></a>什么是 Rerank</h3><p>Rerank 并不是新兴的技术，其发展历史可追溯到搜索引擎，其历程可浓缩为 3 个主要阶段：</p><figure class="image-bubble"><div class="img-lightbox"><div class="overlay"></div> <img src="https://cdn.jsdelivr.net/gh/SimonAKing/images/loading/4-min.gif" alt="image" title="Rerank-从 BERT 到大模型的技术旅程/timeline.png" data-original="https://cdn.jsdelivr.net/gh/SimonAKing/blog/rerank/timeline.png"></div><div class="image-caption">Rerank-从 BERT 到大模型的技术旅程/timeline.png</div></figure><p>一句话介绍：Rerank 是一种对初步检索结果进行重排序的优化技术，以提高问答结果的准确性。</p><p>在 RAG 应用中，如果没有 rerank 会给到模型 粗召后的文档，会出现文档与 query 深层语义相关性不足（仅表面相似）问题，导致生成质量下降。</p><p>一个 bad case：</p><div class="image-row"><figure class="image-bubble row-image"><div class="img-lightbox"><div class="overlay"></div> <img src="https://cdn.jsdelivr.net/gh/SimonAKing/images/loading/4-min.gif" alt="image" title="Rerank-从 BERT 到大模型的技术旅程/badcase.png" data-original="https://cdn.jsdelivr.net/gh/SimonAKing/blog/rerank/badcase.png"></div><div class="image-caption">Rerank-从 BERT 到大模型的技术旅程/badcase.png</div></figure><figure class="image-bubble row-image"><div class="img-lightbox"><div class="overlay"></div> <img src="https://cdn.jsdelivr.net/gh/SimonAKing/images/loading/1-min.gif" alt="image" title="Rerank-从 BERT 到大模型的技术旅程/Influence.png" data-original="https://cdn.jsdelivr.net/gh/SimonAKing/blog/rerank/Influence.png"></div><div class="image-caption">Rerank-从 BERT 到大模型的技术旅程/Influence.png</div></figure></div><p><em>不相关段落对于 RAG 效果的影响 <a href="https://arxiv.org/pdf/2410.05983" target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/pdf/2410.05983</a></em></p><p>具体而言，rerank 的加持会带来：</p><ol><li><p>排除无关信息：Rerank 会进一步深度理解语义，从向量的相似度、关键词的词频权重到理解复杂语义（如 cross-encoder 架构）；</p></li><li><p>有更多排序可能性：能够增加多维度的特征进行加权计算（如 文档完整性、时效性、权威性..) ;</p></li><li><p>能基于文档上下文、query 意图排序：排序后的文档 不仅是语义关联，还能提升准确反映 query 真实意图的文档权重。</p><p>举个例子：query 是某个 topic 相关的问答，如：苹果公司最新的产品发布会有哪些亮点？</p></li></ol><p>再精排后，可以再进一步过滤 低相关的 documents 或者 基于模型窗口限制、注意力缺陷（如 lost in the middle），根据 相关分数 重排 documents ，能够有效提升 RAG 应用的问答效果。</p><h3 id="业界实践"><a href="#业界实践" class="headerlink" title="业界实践"></a>业界实践</h3><p>因为涉及到了精排，所以会产生额外的延迟；且 rerank 模型也需要一定的参数量，对于长尾场景可能也会有偏差。近年来的研究已经提出了多种创新方法来应对这些挑战。以下将介绍一些具有代表性的论文。</p><h4 id="Passage-Re-ranking-with-BERT"><a href="#Passage-Re-ranking-with-BERT" class="headerlink" title="Passage Re-ranking with BERT"></a><a href="https://arxiv.org/abs/1901.04085" target="_blank" rel="external nofollow noopener noreferrer">Passage Re-ranking with BERT</a></h4><blockquote><p>📄 Paper: <a href="https://arxiv.org/abs/1901.04085" target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/abs/1901.04085</a></p></blockquote><p>该工作开创性地提出了一种基于 BERT 的 rerank 模型，证明了 预训练模型在 rerank 任务的效果，也影响了后续相关的研究工作。</p><figure class="image-bubble"><div class="img-lightbox"><div class="overlay"></div> <img src="https://cdn.jsdelivr.net/gh/SimonAKing/images/loading/3-min.gif" alt="image" title="Rerank-从 BERT 到大模型的技术旅程/p1.png" data-original="https://cdn.jsdelivr.net/gh/SimonAKing/blog/rerank/p1.png"></div><div class="image-caption">Rerank-从 BERT 到大模型的技术旅程/p1.png</div></figure><p>核心思路是将 rerank 视为 二分类任务，假设输入是 query-document pairs，会采取 point-wise 思路（二分类）将 query-document 拼接成单个序列：[CLS] query [SEP] document [SEP]，[SEP] 分割后的 token 会增加 token_type_ids 作为 llm embedding 的一部分（辅助信息 用于区分 query 与 document）。</p><p>经过 多层 self-attention，[CLS] token 能表示 query 与 document 的匹配度，最后通过一个分类层预测 [CLS] token 表示的相关性得分。</p><p>训练时，相关的数据作为正样本，不相关的数据作为负样本，使用交叉熵损失进行优化。</p><p>关键代码介绍：</p><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SimpleBertReranker</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, bert_model_name=<span class="string">'bert-base-uncased'</span>)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.bert = BertModel.from_pretrained(bert_model_name)</span><br><span class="line">        self.classifier = nn.Linear(self.bert.config.hidden_size, <span class="number">1</span>)  <span class="comment"># 分类层</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, input_ids, attention_mask, token_type_ids)</span>:</span></span><br><span class="line">        <span class="comment"># 获取 BERT 的输出</span></span><br><span class="line">        outputs = self.bert(input_ids=input_ids,</span><br><span class="line">                            attention_mask=attention_mask,</span><br><span class="line">                            token_type_ids=token_type_ids)</span><br><span class="line">        <span class="comment"># 使用 [CLS] token 的表示</span></span><br><span class="line">        cls_output = outputs.pooler_output</span><br><span class="line">        <span class="comment"># 通过分类层得到相关性得分</span></span><br><span class="line">        score = self.classifier(cls_output)</span><br><span class="line">        <span class="keyword">return</span> score</span><br><span class="line"></span><br><span class="line">tokenizer = BertTokenizer.from_pretrained(<span class="string">'bert-base-uncased'</span>)</span><br><span class="line">query = <span class="string">"What is the capital of France?"</span></span><br><span class="line">document = <span class="string">"Paris is the capital of France."</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 编码输入</span></span><br><span class="line">inputs = tokenizer(query, document, return_tensors=<span class="string">'pt'</span>, padding=<span class="literal">True</span>, truncation=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化模型</span></span><br><span class="line">model = SimpleBertReranker()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算相关性得分</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    score = model(**inputs)</span><br><span class="line">    print(<span class="string">"Relevance score:"</span>, score.item())</span><br></pre></td></tr></tbody></table></figure><p></p><h4 id="Document-Ranking-with-a-Pretrained-Sequence-to-Sequence-Model"><a href="#Document-Ranking-with-a-Pretrained-Sequence-to-Sequence-Model" class="headerlink" title="Document Ranking with a Pretrained Sequence-to-Sequence Model"></a><a href="https://arxiv.org/abs/2003.06713" target="_blank" rel="external nofollow noopener noreferrer">Document Ranking with a Pretrained Sequence-to-Sequence Model</a></h4><blockquote><p>📄 Paper: <a href="https://arxiv.org/abs/2003.06713" target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/abs/2003.06713</a></p></blockquote><p>该工作提出了一种不同于 BERT 模型 分类任务的方式，基于 T5 模型 将 rerank 视为生成任务。</p><div class="image-row"><figure class="image-bubble row-image"><div class="img-lightbox"><div class="overlay"></div> <img src="https://cdn.jsdelivr.net/gh/SimonAKing/images/loading/2-min.gif" alt="image" title="Rerank-从 BERT 到大模型的技术旅程/p2.png" data-original="https://cdn.jsdelivr.net/gh/SimonAKing/blog/rerank/p2.png"></div><div class="image-caption">Rerank-从 BERT 到大模型的技术旅程/p2.png</div></figure><figure class="image-bubble row-image"><div class="img-lightbox"><div class="overlay"></div> <img src="https://cdn.jsdelivr.net/gh/SimonAKing/images/loading/3-min.gif" alt="image" title="Rerank-从 BERT 到大模型的技术旅程/p3.png" data-original="https://cdn.jsdelivr.net/gh/SimonAKing/blog/rerank/p3.png"></div><div class="image-caption">Rerank-从 BERT 到大模型的技术旅程/p3.png</div></figure></div><p>输入序列的格式是 Query: q Document: d Relevant: 格式，输出是 true、false 这两种 token。</p><p>在训练时，模型被微调为根据正负样本输出 “true” 或 “false” 作为目标 token；在推理阶段 通过对目标 token 进行 softmax 计算概率来进行重排。</p><p>关键代码介绍：</p><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">T5Reranker</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment"># 加载预训练的 T5 模型</span></span><br><span class="line">        self.model = load_pretrained_t5()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">prepare_input</span><span class="params">(self, query, document)</span>:</span></span><br><span class="line">        <span class="comment"># 构造输入序列格式</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">f"Query: <span class="subst">{query}</span> Document: <span class="subst">{document}</span> Relevant:"</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fine_tune</span><span class="params">(self, train_data)</span>:</span></span><br><span class="line">        <span class="string">"""训练过程</span></span><br><span class="line"><span class="string">        train_data: [(query, document, is_relevant), ...]</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">for</span> query, document, is_relevant <span class="keyword">in</span> train_data:</span><br><span class="line">            input_text = self.prepare_input(query, document)</span><br><span class="line">            target = <span class="string">"true"</span> <span class="keyword">if</span> is_relevant <span class="keyword">else</span> <span class="string">"false"</span></span><br><span class="line">            self.model.train(input_text, target)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">rerank</span><span class="params">(self, query, candidate_documents)</span>:</span></span><br><span class="line">        <span class="string">"""重排序过程"""</span></span><br><span class="line">        results = []</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> doc <span class="keyword">in</span> candidate_documents:</span><br><span class="line">            <span class="comment"># 构造输入序列</span></span><br><span class="line">            input_text = self.prepare_input(query, doc)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 获取模型输出的 logits</span></span><br><span class="line">            logits = self.model.get_logits(input_text)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 只对"true"和"false" token 计算 softmax</span></span><br><span class="line">            true_false_logits = logits[[<span class="string">"true_token_id"</span>, <span class="string">"false_token_id"</span>]]</span><br><span class="line">            probs = softmax(true_false_logits)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 使用"true" token 的概率作为相关性分数</span></span><br><span class="line">            relevance_score = probs[<span class="string">"true_token_id"</span>]</span><br><span class="line">            results.append((doc, relevance_score))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 根据相关性分数排序</span></span><br><span class="line">        ranked_docs = sorted(results, key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>], reverse=<span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">return</span> ranked_docs</span><br></pre></td></tr></tbody></table></figure><p></p><h4 id="Is-ChatGPT-Good-at-Search-Investigating-Large-Language-Models-as-Re-Ranking-Agents"><a href="#Is-ChatGPT-Good-at-Search-Investigating-Large-Language-Models-as-Re-Ranking-Agents" class="headerlink" title="Is ChatGPT Good at Search? Investigating Large Language Models as Re-Ranking Agents"></a><a href="https://arxiv.org/abs/2304.09542" target="_blank" rel="external nofollow noopener noreferrer">Is ChatGPT Good at Search? Investigating Large Language Models as Re-Ranking Agents</a></h4><blockquote><p>📄 Paper: <a href="https://arxiv.org/abs/2304.09542" target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/abs/2304.09542</a></p></blockquote><p>该工作调研了 GPT 模型（GPT-4） 在 rerank 任务上的表现，基于当时的 sota 模型（GPT4）再结合合适的方法（滑动窗口+ listwise），可使得 GPT 模型达到 SOTA 结果。</p><div class="image-row"><figure class="image-bubble row-image"><div class="img-lightbox"><div class="overlay"></div> <img src="https://cdn.jsdelivr.net/gh/SimonAKing/images/loading/4-min.gif" alt="image" title="Rerank-从 BERT 到大模型的技术旅程/p4.png" data-original="https://cdn.jsdelivr.net/gh/SimonAKing/blog/rerank/p4.png"></div><div class="image-caption">Rerank-从 BERT 到大模型的技术旅程/p4.png</div></figure><figure class="image-bubble row-image"><div class="img-lightbox"><div class="overlay"></div> <img src="https://cdn.jsdelivr.net/gh/SimonAKing/images/loading/2-min.gif" alt="image" title="Rerank-从 BERT 到大模型的技术旅程/p5.png" data-original="https://cdn.jsdelivr.net/gh/SimonAKing/blog/rerank/p5.png"></div><div class="image-caption">Rerank-从 BERT 到大模型的技术旅程/p5.png</div></figure></div><p>通过图 c 的 prompt 要求 LLMs 生成相关性的段落 ID，如果超出模型窗口时 会使用 滑动窗口策略：</p><p>首先对（M-w）到 M 的段落进行排名，然后滑动窗口，对（M-w-s）到（M-s）的段落重新排名，重复此过程直到所有段落都被重新排名。</p><figure class="image-bubble"><div class="img-lightbox"><div class="overlay"></div> <img src="https://cdn.jsdelivr.net/gh/SimonAKing/images/loading/3-min.gif" alt="image" title="Rerank-从 BERT 到大模型的技术旅程/p6.png" data-original="https://cdn.jsdelivr.net/gh/SimonAKing/blog/rerank/p6.png"></div><div class="image-caption">Rerank-从 BERT 到大模型的技术旅程/p6.png</div></figure><h4 id="Large-Language-Models-are-Effective-Text-Rankers"><a href="#Large-Language-Models-are-Effective-Text-Rankers" class="headerlink" title="Large Language Models are Effective Text Rankers"></a><a href="https://arxiv.org/abs/2306.17563" target="_blank" rel="external nofollow noopener noreferrer">Large Language Models are Effective Text Rankers</a></h4><blockquote><p>📄 Paper: <a href="https://arxiv.org/abs/2306.17563" target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/abs/2306.17563</a></p></blockquote><p>上篇工作证明了使用 LLMs 在 rerank 场景的效果，不过由于其黑盒，并且对初始段落顺序的敏感（使用 BM25 召回的顺序会优于随机顺序），仅能依靠商业大模型（开源模型失败率高），研究价值不高。</p><p>不同于基于 sota 模型做 listwise，该工作提出了 PRP（Pairwise Ranking Prompting） 一种新策略（下图 1），核心思路是 拆解问题，每个任务的难度降低，对 LLMs 的能力要求也会降低。</p><p>通过合适的评分机制 再结合高效的排序方式，能做到在 小模型上达到不错效果。</p><div class="image-row"><figure class="image-bubble row-image"><div class="img-lightbox"><div class="overlay"></div> <img src="https://cdn.jsdelivr.net/gh/SimonAKing/images/loading/3-min.gif" alt="image" title="Rerank-从 BERT 到大模型的技术旅程/p7.png" data-original="https://cdn.jsdelivr.net/gh/SimonAKing/blog/rerank/p7.png"></div><div class="image-caption">Rerank-从 BERT 到大模型的技术旅程/p7.png</div></figure><figure class="image-bubble row-image"><div class="img-lightbox"><div class="overlay"></div> <img src="https://cdn.jsdelivr.net/gh/SimonAKing/images/loading/4-min.gif" alt="image" title="Rerank-从 BERT 到大模型的技术旅程/p8.png" data-original="https://cdn.jsdelivr.net/gh/SimonAKing/blog/rerank/p8.png"></div><div class="image-caption">Rerank-从 BERT 到大模型的技术旅程/p8.png</div></figure></div><h4 id="Leveraging-Passage-Embeddings-for-Efficient-Listwise-Reranking-with-Large-Language-Models"><a href="#Leveraging-Passage-Embeddings-for-Efficient-Listwise-Reranking-with-Large-Language-Models" class="headerlink" title="Leveraging Passage Embeddings for Efficient Listwise Reranking with Large Language Models"></a><a href="https://arxiv.org/abs/2406.14848" target="_blank" rel="external nofollow noopener noreferrer">Leveraging Passage Embeddings for Efficient Listwise Reranking with Large Language Models</a></h4><blockquote><p>📄 Paper: <a href="https://arxiv.org/abs/2406.14848" target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/abs/2406.14848</a></p></blockquote><p>上面两篇工作都是基于 LLMs 进行 rerank 任务，但 LLMs 会有幻觉以及 latency 居高不下的问题，本篇工作提出了一种 PE Rank 的技术。</p><p>仍然采用 listwise 的方式，有两种 document 的处理方式，其中一种是不会将召回的 document 给到 LLMs，而是会将 document 替换成 特殊标记，类似于 soft prompt，prompt 如下：</p><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">I will provide you with {{n}} passages, each with a special token representing the passage</span><br><span class="line">enclosed in [].</span><br><span class="line">Rank the passages based on their relevance to the search query: {{query}}.</span><br><span class="line">Passage 1: [{{embedding}}]</span><br><span class="line">...</span><br><span class="line">Passage {{n}}: [{{embedding}}]</span><br><span class="line">Search Query: {{query}}</span><br><span class="line">Rank the {{n}} passages above based on their relevance to the search query in descending order.</span><br><span class="line">Only output the {{n}} unique special token in the ranking.</span><br></pre></td></tr></tbody></table></figure><p></p><figure class="image-bubble"><div class="img-lightbox"><div class="overlay"></div> <img src="https://cdn.jsdelivr.net/gh/SimonAKing/images/loading/2-min.gif" alt="image" title="Rerank-从 BERT 到大模型的技术旅程/p9.png" data-original="https://cdn.jsdelivr.net/gh/SimonAKing/blog/rerank/p9.png"></div><div class="image-caption">Rerank-从 BERT 到大模型的技术旅程/p9.png</div></figure><p>核心有两点：</p><ol><li>在输入时通过一个训练好的 mlp 层将 token embedding 映射成 llm embedding，能够压缩文档上下文（类似于 xRag），给到模型的输入见图 3。</li><li>输出时约束了 decode ，解码空间 仅能包含文档 ID，能根治 LLMs 的幻觉问题，因为 词表空间变小了，所以也加快了生成速度。</li></ol><p>相应的在训练时，分两阶段 输入的映射层训练，以及 decoding 时的排序学习训练。</p><h4 id="业界进展"><a href="#业界进展" class="headerlink" title="业界进展"></a>业界进展</h4><p>近一年，多家组织/公司 推出了各自的 rerank 模型，一些亮点：</p><table><thead><tr><th>模型</th><th>发布时间</th><th>亮点</th></tr></thead><tbody><tr><td>Cohere Rerank-3.5</td><td>2024/12/3</td><td>- 相比前代模型提升了 10% 的准确率</td></tr><tr><td>Jina Reranker v2</td><td>2024/06/25</td><td>- 支持跨语言重排（cross-lingual reranking）</td></tr><tr><td>BGE Re-Ranker v2.0</td><td>2024/03/18</td><td>- 在 MTEB 重排任务上达到 SOTA 水平</td></tr></tbody></table><p>这些进展表明，rerank 未来会向着更高的准确率和更低的 latency 发展，使用场景也不会局限于 文档排序。</p><hr><h2 id="结束语"><a href="#结束语" class="headerlink" title="结束语"></a>结束语</h2><p>通过对 rerank 技术的深入探讨，我们可以看到：</p><ol><li><p>技术演进趋势</p><ul><li>从简单的 BERT 二分类，到 T5 生成式方法，再到利用大模型能力，rerank 技术在不断创新</li><li>业界正在探索如何平衡效果与效率，比如通过 embedding 压缩、约束解码等方式优化性能</li><li>开源社区和商业产品都在积极推进，为不同场景提供了丰富的选择</li></ul></li><li><p>对业务的价值</p><ul><li>提升搜索质量：通过深度语义理解，能更准确地识别用户意图，减少无关结果</li><li>优化 RAG 应用：通过精准的文档筛选和重排，显著提升大模型问答的准确性</li><li>支持多样化场景：<ul><li>产品分析：更准确地发现用户反馈，包括应用商店评论、社交媒体讨论等</li><li>信息转化：提高相关信息的发现效率，降低噪音</li><li>对话应用：提供更精准的知识库匹配</li><li>…</li></ul></li></ul></li></ol><p>回顾 rerank 的发展历程，从 BERT 二分类到基于 LLM 策略的工作，技术在不断突破；从单一的搜索场景到如今的 RAG 应用，价值在持续提升。随着 AI 应用的普及，rerank 作为连接召回和生成的关键环节，在提升问答质量方面发挥着重要的作用。</p><p>欢迎转载本站文章，请注明作者和出处 <a href="http://simonaking.com">SimonAKing</a>。</p></div><div class="recommended_posts"><div class="recommended_wrap"><h2 class="recommended_title">相关文章</h2><ul class="popular-posts"><li class="popular-posts-item"><div class="popular-posts-title"> <a href="/blog/llm-inference-optimization-en/" rel="bookmark">LLM Inference Optimization Overview - From Data to System Architecture</a></div></li><li class="popular-posts-item"><div class="popular-posts-title"> <a href="/blog/llm-inference-optimization/" rel="bookmark">聊聊大模型推理加速：从数据到系统的技术概要</a></div></li></ul></div></div><blockquote class="post-copyright"><div class="content"> <span class="post-time">最后更新：<time datetime="2025-05-02T08:30:48.354Z">2025-05-02 16:30:48</time></span> 原文链接：<a href="/blog/rerank/" target="_blank" rel="external">https://simonaking.com/blog/rerank/</a></div><footer><ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/LLM/" rel="tag">LLM</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/Rerank/" rel="tag">Rerank</a></li></ul><div> <img itemprop="image" lass="copyimg" src="https://cdn.jsdelivr.net/gh/SimonAKing/images/blog/avatar.jpg" alt="SimonAKing"> <a itemprop="author" itemscope itemtype="http://schema.org/Person" href="/blog">SimonAKing</a></div></footer></blockquote></div><section class="comments" id="comments"><div id="disqus_thread"></div></section></article></div></main><div class="mask" id="mask"></div><a href="javascript:;" id="gotop" class="fade-scale waves-effect waves-circle waves-light"><span class="icon icon-lg icon-chevronup"></span></a><div class="search-panel in_post" id="search-panel"><ul class="search-result" id="search-result"></ul></div><template id="search-tpl"><li class="item waves-block waves-effect" onclick="location.href='{path}'" data-path="{path}"><div class="title ellipsis" title="{title}">{title}</div></li></template><div id="color-picker" class="page-modal"><a class="close" href="javascript:;"><i class="icon icon-close2"></i></a><br><h4><i class="icon icon-quote-left"></i> <span>RGB调色实验室 🎨</span><i class="icon icon-quote-right"></i></h4><div id="color-picker-container"></div></div><div id="wechat" class="page-modal wechat-wrap"><a class="close" href="javascript:;"><i class="icon icon-close2"></i></a><br><h4 class="wechat-title"> <span style="font-size: 18px">欢迎添加我的微信，进群交流、学习<br><i class="icon icon-quote-left"></i> simonaking<i class="icon icon-quote-right"></i></span></h4> <img id="wechat_img" src="https://cdn.jsdelivr.net/gh/SimonAKing/images/blog/wx.png" alt="欢迎您的关注！" style="margin-top: 5%"></div><script src="https://simonaking.com/registerSW.js?v=7d04115230169"></script><script src="https://cdn.jsdelivr.net/gh/SimonAKing/js/log.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-waves@0.7.6/src/js/waves.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/headroom.js@0.12.0/dist/headroom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@jaames/iro@5.2.3/dist/iro.min.js"></script><script src="https://cdn.jsdelivr.net/gh/SimonAKing/blog@7d04115230169/js/particles-585dd6bbf8.js"></script><script src="https://cdn.jsdelivr.net/gh/SimonAKing/blog@7d04115230169/js/main-c5641580d9.js"></script><script src="https://cdn.jsdelivr.net/gh/SimonAKing/blog@7d04115230169/js/script-66d90ba09e.js"></script><script src="https://cdn.jsdelivr.net/gh/SimonAKing/blog@7d04115230169/js/module/hover-effect-e72a114ce3.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@5.1.0/instantpage.min.js"></script><script src="https://cdn.jsdelivr.net/gh/SimonAKing/blog@7d04115230169/js/module/post-6d3f729af5.js"></script><script defer src="https://cdn.jsdelivr.net/gh/SimonAKing/blog@7d04115230169/js/module/comment-5cad405b01.js"></script><script defer src="https://cdn.jsdelivr.net/gh/SimonAKing/js/translate-ff7607fcb8.js"></script></body></html>